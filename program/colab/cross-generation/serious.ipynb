{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOUCXh+XmxB3nmCBkhyN1Jk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","from natsort import natsorted\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.metrics import accuracy_score, r2_score\n","import gc\n","import numpy as np\n","import os\n","import pandas as pd\n","import warnings\n","drive.mount('/content/drive')\n","warnings.filterwarnings('ignore')\n","root_folder = '/content/drive/MyDrive/aaa/datasets'\n","def find_and_sort_csv_files(folder):\n","    csv_files = []\n","    for root, dirs, files in os.walk(folder):\n","        for file in files:\n","            if file.endswith('.csv'):\n","                csv_files.append(os.path.join(root, file))\n","    csv_files_sorted = natsorted(csv_files)\n","    return csv_files_sorted\n","all_csv_files_sorted = find_and_sort_csv_files(root_folder)\n","num_past_measurements = 20\n","feature_name = 'HISTORY' ########################################################\n","def process_dataset(file_path):\n","    data = pd.read_csv(file_path)\n","    data = data.head(int(np.round(len(data) * 0.1)))\n","    data = data.reset_index()\n","    test_size = int(np.round(len(data) * test_ratio))\n","    train_data, test_data = data[:-test_size], data[-test_size:]\n","    num_columns = train_data.shape[1]\n","    prediction_indices = range(len(train_data), len(train_data) + test_size)\n","    prediction_data = pd.DataFrame(prediction_indices, columns=['index'], index=prediction_indices)\n","    for col in [column for column in train_data.columns if train_data[column].nunique() == 1]:\n","        prediction_data[col] = pd.Series(train_data[col].iloc[0]).repeat(test_size).values\n","    columns_not_in_prediction = [col for col in train_data.columns.tolist() if col not in prediction_data.columns.tolist()]\n","    unique_values_dict = {}\n","    for col in columns_not_in_prediction:\n","        unique_values = train_data[col].nunique()\n","        unique_values_dict[col] = unique_values\n","    continuous_columns = []\n","    discrete_columns = []\n","    for col, unique_values in unique_values_dict.items():\n","        if unique_values > 500:\n","            continuous_columns.append(col)\n","        else:\n","            discrete_columns.append(col)\n","    start_index = len(data) - test_size\n","    for col in columns_not_in_prediction:\n","        for i in range(1, num_past_measurements + 1):\n","            data[f'{col}_{i}'] = data[col].shift(i * 25)\n","            if data[f'{col}_{i}'].dtype == 'int64':\n","                data[f'{col}_{i}'].fillna(-1, inplace=True)\n","            elif data[f'{col}_{i}'].dtype == 'float64':\n","                data[f'{col}_{i}'].fillna(-1.0, inplace=True)\n","            if data[f'{col}_{i}'].dtype != data[col].dtype:\n","                data[f'{col}_{i}'] = data[f'{col}_{i}'].astype(data[col].dtype)\n","            train_data.loc[:start_index, f'{col}_{i}'] = data.loc[:start_index, f'{col}_{i}']\n","            test_data.loc[:start_index, f'{col}_{i}'] = data.loc[:start_index, f'{col}_{i}']\n","            prediction_data.loc[start_index:, f'{col}_{i}'] = data.loc[start_index:, f'{col}_{i}']\n","    num_rows = int(np.round(len(train_data) * 0.05))\n","    for col in columns_not_in_prediction:\n","        features = [f'{col}_{i}' for i in range(1, num_columns)]\n","        X_test = prediction_data[features]\n","        if col in continuous_columns:\n","            X_train = train_data[features].values[-num_rows:]\n","            y_train = train_data[col].values[-num_rows:]\n","            model = LinearRegression()\n","        else:\n","            X_train = train_data[features]\n","            y_train = train_data[col]\n","            model = LogisticRegression(max_iter=1000)\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","        y_pred = np.where(y_pred < -1, -1, y_pred)\n","        if train_data[col].dtype == np.int64:\n","            y_pred = np.round(y_pred).astype(np.int64)\n","        prediction_data[col] = y_pred\n","    columns_to_drop = ['index']\n","    if columns_not_in_prediction:\n","        start_index = train_data.columns.get_loc(f'{columns_not_in_prediction[0]}_1')\n","        end_index = train_data.columns.get_loc(f'{columns_not_in_prediction[-1]}_{num_past_measurements}')\n","        columns_to_drop.extend(data.columns[start_index:end_index + 1])\n","    data = data.drop(columns_to_drop, axis=1)\n","    train_data = train_data.drop(columns_to_drop, axis=1)\n","    test_data = test_data.drop(columns_to_drop, axis=1)\n","    prediction_data = prediction_data.drop(columns_to_drop, axis=1)\n","    prediction_data = prediction_data[train_data.columns]\n","    scores = {}\n","    for col in prediction_data.columns:\n","        if col in continuous_columns:\n","            score = r2_score(test_data[col], prediction_data[col])\n","            if score < 0:\n","                score = 0\n","            metric = 'R-squared'\n","        else:\n","            score = accuracy_score(test_data[col], prediction_data[col])\n","            metric = 'Accuracy'\n","        scores[col] = (score, metric)\n","    average_score = np.mean([score for score, metric in scores.values()])\n","    average_score = round(average_score * 100, 2)\n","    del data\n","    del train_data\n","    del test_data\n","    del prediction_data\n","    del scores\n","    return average_score\n","for csv_file in all_csv_files_sorted:\n","    file_path = os.path.join(root_folder, csv_file)\n","    average_score = process_dataset(file_path)\n","    print(file_path)\n","    print(average_score, '%')\n","    print()\n","    del file_path\n","    del average_score\n","    gc.collect()"],"metadata":{"id":"75ViniWoXazb"},"execution_count":null,"outputs":[]}]}